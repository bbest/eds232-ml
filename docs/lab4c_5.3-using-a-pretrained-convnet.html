<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ad0000; } /* Alert */
code span.an { color: #5e5e5e; } /* Annotation */
code span.at { } /* Attribute */
code span.bn { color: #ad0000; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007ba5; } /* ControlFlow */
code span.ch { color: #20794d; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #5e5e5e; } /* Comment */
code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
code span.dt { color: #ad0000; } /* DataType */
code span.dv { color: #ad0000; } /* DecVal */
code span.er { color: #ad0000; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #ad0000; } /* Float */
code span.fu { color: #4758ab; } /* Function */
code span.im { } /* Import */
code span.in { color: #5e5e5e; } /* Information */
code span.kw { color: #007ba5; } /* Keyword */
code span.op { color: #5e5e5e; } /* Operator */
code span.ot { color: #007ba5; } /* Other */
code span.pp { color: #ad0000; } /* Preprocessor */
code span.sc { color: #5e5e5e; } /* SpecialChar */
code span.ss { color: #20794d; } /* SpecialString */
code span.st { color: #20794d; } /* String */
code span.va { color: #111111; } /* Variable */
code span.vs { color: #20794d; } /* VerbatimString */
code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
</style>


  <!--radix_placeholder_meta_tags-->
  <title>EDS 232: lab4c_5.3-using-a-pretrained-convnet</title>




  <!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
  <meta property="og:title" content="EDS 232: lab4c_5.3-using-a-pretrained-convnet"/>
  <meta property="og:type" content="article"/>
  <meta property="og:locale" content="en_US"/>
  <meta property="og:site_name" content="EDS 232"/>

  <!--  https://dev.twitter.com/cards/types/summary -->
  <meta property="twitter:card" content="summary"/>
  <meta property="twitter:title" content="EDS 232: lab4c_5.3-using-a-pretrained-convnet"/>

  <!--/radix_placeholder_meta_tags-->
  <!--radix_placeholder_rmarkdown_metadata-->

  <script type="text/json" id="radix-rmarkdown-metadata">
  {"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","output"]}},"value":[{"type":"character","attributes":{},"value":["lab4c_5.3-using-a-pretrained-convnet"]},{"type":"character","attributes":{},"value":["html_document"]}]}
  </script>
  <!--/radix_placeholder_rmarkdown_metadata-->
  <!--radix_placeholder_navigation_in_header-->
  <meta name="distill:offset" content=""/>

  <script type="application/javascript">

    window.headroom_prevent_pin = false;

    window.document.addEventListener("DOMContentLoaded", function (event) {

      // initialize headroom for banner
      var header = $('header').get(0);
      var headerHeight = header.offsetHeight;
      var headroom = new Headroom(header, {
        tolerance: 5,
        onPin : function() {
          if (window.headroom_prevent_pin) {
            window.headroom_prevent_pin = false;
            headroom.unpin();
          }
        }
      });
      headroom.init();
      if(window.location.hash)
        headroom.unpin();
      $(header).addClass('headroom--transition');

      // offset scroll location for banner on hash change
      // (see: https://github.com/WickyNilliams/headroom.js/issues/38)
      window.addEventListener("hashchange", function(event) {
        window.scrollTo(0, window.pageYOffset - (headerHeight + 25));
      });

      // responsive menu
      $('.distill-site-header').each(function(i, val) {
        var topnav = $(this);
        var toggle = topnav.find('.nav-toggle');
        toggle.on('click', function() {
          topnav.toggleClass('responsive');
        });
      });

      // nav dropdowns
      $('.nav-dropbtn').click(function(e) {
        $(this).next('.nav-dropdown-content').toggleClass('nav-dropdown-active');
        $(this).parent().siblings('.nav-dropdown')
           .children('.nav-dropdown-content').removeClass('nav-dropdown-active');
      });
      $("body").click(function(e){
        $('.nav-dropdown-content').removeClass('nav-dropdown-active');
      });
      $(".nav-dropdown").click(function(e){
        e.stopPropagation();
      });
    });
  </script>

  <style type="text/css">

  /* Theme (user-documented overrideables for nav appearance) */

  .distill-site-nav {
    color: rgba(255, 255, 255, 0.8);
    background-color: #0F2E3D;
    font-size: 15px;
    font-weight: 300;
  }

  .distill-site-nav a {
    color: inherit;
    text-decoration: none;
  }

  .distill-site-nav a:hover {
    color: white;
  }

  @media print {
    .distill-site-nav {
      display: none;
    }
  }

  .distill-site-header {

  }

  .distill-site-footer {

  }


  /* Site Header */

  .distill-site-header {
    width: 100%;
    box-sizing: border-box;
    z-index: 3;
  }

  .distill-site-header .nav-left {
    display: inline-block;
    margin-left: 8px;
  }

  @media screen and (max-width: 768px) {
    .distill-site-header .nav-left {
      margin-left: 0;
    }
  }


  .distill-site-header .nav-right {
    float: right;
    margin-right: 8px;
  }

  .distill-site-header a,
  .distill-site-header .title {
    display: inline-block;
    text-align: center;
    padding: 14px 10px 14px 10px;
  }

  .distill-site-header .title {
    font-size: 18px;
    min-width: 150px;
  }

  .distill-site-header .logo {
    padding: 0;
  }

  .distill-site-header .logo img {
    display: none;
    max-height: 20px;
    width: auto;
    margin-bottom: -4px;
  }

  .distill-site-header .nav-image img {
    max-height: 18px;
    width: auto;
    display: inline-block;
    margin-bottom: -3px;
  }



  @media screen and (min-width: 1000px) {
    .distill-site-header .logo img {
      display: inline-block;
    }
    .distill-site-header .nav-left {
      margin-left: 20px;
    }
    .distill-site-header .nav-right {
      margin-right: 20px;
    }
    .distill-site-header .title {
      padding-left: 12px;
    }
  }


  .distill-site-header .nav-toggle {
    display: none;
  }

  .nav-dropdown {
    display: inline-block;
    position: relative;
  }

  .nav-dropdown .nav-dropbtn {
    border: none;
    outline: none;
    color: rgba(255, 255, 255, 0.8);
    padding: 16px 10px;
    background-color: transparent;
    font-family: inherit;
    font-size: inherit;
    font-weight: inherit;
    margin: 0;
    margin-top: 1px;
    z-index: 2;
  }

  .nav-dropdown-content {
    display: none;
    position: absolute;
    background-color: white;
    min-width: 200px;
    border: 1px solid rgba(0,0,0,0.15);
    border-radius: 4px;
    box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.1);
    z-index: 1;
    margin-top: 2px;
    white-space: nowrap;
    padding-top: 4px;
    padding-bottom: 4px;
  }

  .nav-dropdown-content hr {
    margin-top: 4px;
    margin-bottom: 4px;
    border: none;
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }

  .nav-dropdown-active {
    display: block;
  }

  .nav-dropdown-content a, .nav-dropdown-content .nav-dropdown-header {
    color: black;
    padding: 6px 24px;
    text-decoration: none;
    display: block;
    text-align: left;
  }

  .nav-dropdown-content .nav-dropdown-header {
    display: block;
    padding: 5px 24px;
    padding-bottom: 0;
    text-transform: uppercase;
    font-size: 14px;
    color: #999999;
    white-space: nowrap;
  }

  .nav-dropdown:hover .nav-dropbtn {
    color: white;
  }

  .nav-dropdown-content a:hover {
    background-color: #ddd;
    color: black;
  }

  .nav-right .nav-dropdown-content {
    margin-left: -45%;
    right: 0;
  }

  @media screen and (max-width: 768px) {
    .distill-site-header a, .distill-site-header .nav-dropdown  {display: none;}
    .distill-site-header a.nav-toggle {
      float: right;
      display: block;
    }
    .distill-site-header .title {
      margin-left: 0;
    }
    .distill-site-header .nav-right {
      margin-right: 0;
    }
    .distill-site-header {
      overflow: hidden;
    }
    .nav-right .nav-dropdown-content {
      margin-left: 0;
    }
  }


  @media screen and (max-width: 768px) {
    .distill-site-header.responsive {position: relative; min-height: 500px; }
    .distill-site-header.responsive a.nav-toggle {
      position: absolute;
      right: 0;
      top: 0;
    }
    .distill-site-header.responsive a,
    .distill-site-header.responsive .nav-dropdown {
      display: block;
      text-align: left;
    }
    .distill-site-header.responsive .nav-left,
    .distill-site-header.responsive .nav-right {
      width: 100%;
    }
    .distill-site-header.responsive .nav-dropdown {float: none;}
    .distill-site-header.responsive .nav-dropdown-content {position: relative;}
    .distill-site-header.responsive .nav-dropdown .nav-dropbtn {
      display: block;
      width: 100%;
      text-align: left;
    }
  }

  /* Site Footer */

  .distill-site-footer {
    width: 100%;
    overflow: hidden;
    box-sizing: border-box;
    z-index: 3;
    margin-top: 30px;
    padding-top: 30px;
    padding-bottom: 30px;
    text-align: center;
  }

  /* Headroom */

  d-title {
    padding-top: 6rem;
  }

  @media print {
    d-title {
      padding-top: 4rem;
    }
  }

  .headroom {
    z-index: 1000;
    position: fixed;
    top: 0;
    left: 0;
    right: 0;
  }

  .headroom--transition {
    transition: all .4s ease-in-out;
  }

  .headroom--unpinned {
    top: -100px;
  }

  .headroom--pinned {
    top: 0;
  }

  /* adjust viewport for navbar height */
  /* helps vertically center bootstrap (non-distill) content */
  .min-vh-100 {
    min-height: calc(100vh - 100px) !important;
  }

  </style>

  <script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
  <link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet"/>
  <link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet"/>
  <script src="site_libs/headroom-0.9.4/headroom.min.js"></script>
  <script src="site_libs/autocomplete-0.37.1/autocomplete.min.js"></script>
  <script src="site_libs/fuse-6.4.1/fuse.min.js"></script>

  <script type="application/javascript">

  function getMeta(metaName) {
    var metas = document.getElementsByTagName('meta');
    for (let i = 0; i < metas.length; i++) {
      if (metas[i].getAttribute('name') === metaName) {
        return metas[i].getAttribute('content');
      }
    }
    return '';
  }

  function offsetURL(url) {
    var offset = getMeta('distill:offset');
    return offset ? offset + '/' + url : url;
  }

  function createFuseIndex() {

    // create fuse index
    var options = {
      keys: [
        { name: 'title', weight: 20 },
        { name: 'categories', weight: 15 },
        { name: 'description', weight: 10 },
        { name: 'contents', weight: 5 },
      ],
      ignoreLocation: true,
      threshold: 0
    };
    var fuse = new window.Fuse([], options);

    // fetch the main search.json
    return fetch(offsetURL('search.json'))
      .then(function(response) {
        if (response.status == 200) {
          return response.json().then(function(json) {
            // index main articles
            json.articles.forEach(function(article) {
              fuse.add(article);
            });
            // download collections and index their articles
            return Promise.all(json.collections.map(function(collection) {
              return fetch(offsetURL(collection)).then(function(response) {
                if (response.status === 200) {
                  return response.json().then(function(articles) {
                    articles.forEach(function(article) {
                      fuse.add(article);
                    });
                  })
                } else {
                  return Promise.reject(
                    new Error('Unexpected status from search index request: ' +
                              response.status)
                  );
                }
              });
            })).then(function() {
              return fuse;
            });
          });

        } else {
          return Promise.reject(
            new Error('Unexpected status from search index request: ' +
                        response.status)
          );
        }
      });
  }

  window.document.addEventListener("DOMContentLoaded", function (event) {

    // get search element (bail if we don't have one)
    var searchEl = window.document.getElementById('distill-search');
    if (!searchEl)
      return;

    createFuseIndex()
      .then(function(fuse) {

        // make search box visible
        searchEl.classList.remove('hidden');

        // initialize autocomplete
        var options = {
          autoselect: true,
          hint: false,
          minLength: 2,
        };
        window.autocomplete(searchEl, options, [{
          source: function(query, callback) {
            const searchOptions = {
              isCaseSensitive: false,
              shouldSort: true,
              minMatchCharLength: 2,
              limit: 10,
            };
            var results = fuse.search(query, searchOptions);
            callback(results
              .map(function(result) { return result.item; })
            );
          },
          templates: {
            suggestion: function(suggestion) {
              var img = suggestion.preview && Object.keys(suggestion.preview).length > 0
                ? `<img src="${offsetURL(suggestion.preview)}"</img>`
                : '';
              var html = `
                <div class="search-item">
                  <h3>${suggestion.title}</h3>
                  <div class="search-item-description">
                    ${suggestion.description || ''}
                  </div>
                  <div class="search-item-preview">
                    ${img}
                  </div>
                </div>
              `;
              return html;
            }
          }
        }]).on('autocomplete:selected', function(event, suggestion) {
          window.location.href = offsetURL(suggestion.path);
        });
        // remove inline display style on autocompleter (we want to
        // manage responsive display via css)
        $('.algolia-autocomplete').css("display", "");
      })
      .catch(function(error) {
        console.log(error);
      });

  });

  </script>

  <style type="text/css">

  .nav-search {
    font-size: x-small;
  }

  /* Algolioa Autocomplete */

  .algolia-autocomplete {
    display: inline-block;
    margin-left: 10px;
    vertical-align: sub;
    background-color: white;
    color: black;
    padding: 6px;
    padding-top: 8px;
    padding-bottom: 0;
    border-radius: 6px;
    border: 1px #0F2E3D solid;
    width: 180px;
  }


  @media screen and (max-width: 768px) {
    .distill-site-nav .algolia-autocomplete {
      display: none;
      visibility: hidden;
    }
    .distill-site-nav.responsive .algolia-autocomplete {
      display: inline-block;
      visibility: visible;
    }
    .distill-site-nav.responsive .algolia-autocomplete .aa-dropdown-menu {
      margin-left: 0;
      width: 400px;
      max-height: 400px;
    }
  }

  .algolia-autocomplete .aa-input, .algolia-autocomplete .aa-hint {
    width: 90%;
    outline: none;
    border: none;
  }

  .algolia-autocomplete .aa-hint {
    color: #999;
  }
  .algolia-autocomplete .aa-dropdown-menu {
    width: 550px;
    max-height: 70vh;
    overflow-x: visible;
    overflow-y: scroll;
    padding: 5px;
    margin-top: 3px;
    margin-left: -150px;
    background-color: #fff;
    border-radius: 5px;
    border: 1px solid #999;
    border-top: none;
  }

  .algolia-autocomplete .aa-dropdown-menu .aa-suggestion {
    cursor: pointer;
    padding: 5px 4px;
    border-bottom: 1px solid #eee;
  }

  .algolia-autocomplete .aa-dropdown-menu .aa-suggestion:last-of-type {
    border-bottom: none;
    margin-bottom: 2px;
  }

  .algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item {
    overflow: hidden;
    font-size: 0.8em;
    line-height: 1.4em;
  }

  .algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item h3 {
    font-size: 1rem;
    margin-block-start: 0;
    margin-block-end: 5px;
  }

  .algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-description {
    display: inline-block;
    overflow: hidden;
    height: 2.8em;
    width: 80%;
    margin-right: 4%;
  }

  .algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview {
    display: inline-block;
    width: 15%;
  }

  .algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img {
    height: 3em;
    width: auto;
    display: none;
  }

  .algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img[src] {
    display: initial;
  }

  .algolia-autocomplete .aa-dropdown-menu .aa-suggestion.aa-cursor {
    background-color: #eee;
  }
  .algolia-autocomplete .aa-dropdown-menu .aa-suggestion em {
    font-weight: bold;
    font-style: normal;
  }

  </style>


  <!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

  <style type="text/css">

  body {
    background-color: white;
  }

  .pandoc-table {
    width: 100%;
  }

  .pandoc-table>caption {
    margin-bottom: 10px;
  }

  .pandoc-table th:not([align]) {
    text-align: left;
  }

  .pagedtable-footer {
    font-size: 15px;
  }

  d-byline .byline {
    grid-template-columns: 2fr 2fr;
  }

  d-byline .byline h3 {
    margin-block-start: 1.5em;
  }

  d-byline .byline .authors-affiliations h3 {
    margin-block-start: 0.5em;
  }

  .authors-affiliations .orcid-id {
    width: 16px;
    height:16px;
    margin-left: 4px;
    margin-right: 4px;
    vertical-align: middle;
    padding-bottom: 2px;
  }

  d-title .dt-tags {
    margin-top: 1em;
    grid-column: text;
  }

  .dt-tags .dt-tag {
    text-decoration: none;
    display: inline-block;
    color: rgba(0,0,0,0.6);
    padding: 0em 0.4em;
    margin-right: 0.5em;
    margin-bottom: 0.4em;
    font-size: 70%;
    border: 1px solid rgba(0,0,0,0.2);
    border-radius: 3px;
    text-transform: uppercase;
    font-weight: 500;
  }

  d-article table.gt_table td,
  d-article table.gt_table th {
    border-bottom: none;
  }

  .html-widget {
    margin-bottom: 2.0em;
  }

  .l-screen-inset {
    padding-right: 16px;
  }

  .l-screen .caption {
    margin-left: 10px;
  }

  .shaded {
    background: rgb(247, 247, 247);
    padding-top: 20px;
    padding-bottom: 20px;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }

  .shaded .html-widget {
    margin-bottom: 0;
    border: 1px solid rgba(0, 0, 0, 0.1);
  }

  .shaded .shaded-content {
    background: white;
  }

  .text-output {
    margin-top: 0;
    line-height: 1.5em;
  }

  .hidden {
    display: none !important;
  }

  d-article {
    padding-top: 2.5rem;
    padding-bottom: 30px;
  }

  d-appendix {
    padding-top: 30px;
  }

  d-article>p>img {
    width: 100%;
  }

  d-article h2 {
    margin: 1rem 0 1.5rem 0;
  }

  d-article h3 {
    margin-top: 1.5rem;
  }

  d-article iframe {
    border: 1px solid rgba(0, 0, 0, 0.1);
    margin-bottom: 2.0em;
    width: 100%;
  }

  /* Tweak code blocks */

  d-article div.sourceCode code,
  d-article pre code {
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  }

  d-article pre,
  d-article div.sourceCode,
  d-article div.sourceCode pre {
    overflow: auto;
  }

  d-article div.sourceCode {
    background-color: white;
  }

  d-article div.sourceCode pre {
    padding-left: 10px;
    font-size: 12px;
    border-left: 2px solid rgba(0,0,0,0.1);
  }

  d-article pre {
    font-size: 12px;
    color: black;
    background: none;
    margin-top: 0;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;

    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;

    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }

  d-article pre a {
    border-bottom: none;
  }

  d-article pre a:hover {
    border-bottom: none;
    text-decoration: underline;
  }

  d-article details {
    grid-column: text;
    margin-bottom: 0.8em;
  }

  @media(min-width: 768px) {

  d-article pre,
  d-article div.sourceCode,
  d-article div.sourceCode pre {
    overflow: visible !important;
  }

  d-article div.sourceCode pre {
    padding-left: 18px;
    font-size: 14px;
  }

  d-article pre {
    font-size: 14px;
  }

  }

  figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }

  /* CSS for d-contents */

  .d-contents {
    grid-column: text;
    color: rgba(0,0,0,0.8);
    font-size: 0.9em;
    padding-bottom: 1em;
    margin-bottom: 1em;
    padding-bottom: 0.5em;
    margin-bottom: 1em;
    padding-left: 0.25em;
    justify-self: start;
  }

  @media(min-width: 1000px) {
    .d-contents.d-contents-float {
      height: 0;
      grid-column-start: 1;
      grid-column-end: 4;
      justify-self: center;
      padding-right: 3em;
      padding-left: 2em;
    }
  }

  .d-contents nav h3 {
    font-size: 18px;
    margin-top: 0;
    margin-bottom: 1em;
  }

  .d-contents li {
    list-style-type: none
  }

  .d-contents nav > ul {
    padding-left: 0;
  }

  .d-contents ul {
    padding-left: 1em
  }

  .d-contents nav ul li {
    margin-top: 0.6em;
    margin-bottom: 0.2em;
  }

  .d-contents nav a {
    font-size: 13px;
    border-bottom: none;
    text-decoration: none
    color: rgba(0, 0, 0, 0.8);
  }

  .d-contents nav a:hover {
    text-decoration: underline solid rgba(0, 0, 0, 0.6)
  }

  .d-contents nav > ul > li > a {
    font-weight: 600;
  }

  .d-contents nav > ul > li > ul {
    font-weight: inherit;
  }

  .d-contents nav > ul > li > ul > li {
    margin-top: 0.2em;
  }


  .d-contents nav ul {
    margin-top: 0;
    margin-bottom: 0.25em;
  }

  .d-article-with-toc h2:nth-child(2) {
    margin-top: 0;
  }


  /* Figure */

  .figure {
    position: relative;
    margin-bottom: 2.5em;
    margin-top: 1.5em;
  }

  .figure img {
    width: 100%;
  }

  .figure .caption {
    color: rgba(0, 0, 0, 0.6);
    font-size: 12px;
    line-height: 1.5em;
  }

  .figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }

  .figure .caption a {
    color: rgba(0, 0, 0, 0.6);
  }

  .figure .caption b,
  .figure .caption strong, {
    font-weight: 600;
    color: rgba(0, 0, 0, 1.0);
  }

  /* Citations */

  d-article .citation {
    color: inherit;
    cursor: inherit;
  }

  div.hanging-indent{
    margin-left: 1em; text-indent: -1em;
  }

  /* Citation hover box */

  .tippy-box[data-theme~=light-border] {
    background-color: rgba(250, 250, 250, 0.95);
  }

  .tippy-content > p {
    margin-bottom: 0;
    padding: 2px;
  }


  /* Tweak 1000px media break to show more text */

  @media(min-width: 1000px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 16px;
    }

    .grid {
      grid-column-gap: 16px;
    }

    d-article {
      font-size: 1.06rem;
      line-height: 1.7em;
    }
    figure .caption, .figure .caption, figure figcaption {
      font-size: 13px;
    }
  }

  @media(min-width: 1180px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 32px;
    }

    .grid {
      grid-column-gap: 32px;
    }
  }


  /* Get the citation styles for the appendix (not auto-injected on render since
     we do our own rendering of the citation appendix) */

  d-appendix .citation-appendix,
  .d-appendix .citation-appendix {
    font-size: 11px;
    line-height: 15px;
    border-left: 1px solid rgba(0, 0, 0, 0.1);
    padding-left: 18px;
    border: 1px solid rgba(0,0,0,0.1);
    background: rgba(0, 0, 0, 0.02);
    padding: 10px 18px;
    border-radius: 3px;
    color: rgba(150, 150, 150, 1);
    overflow: hidden;
    margin-top: -12px;
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  /* Include appendix styles here so they can be overridden */

  d-appendix {
    contain: layout style;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-top: 60px;
    margin-bottom: 0;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    color: rgba(0,0,0,0.5);
    padding-top: 60px;
    padding-bottom: 48px;
  }

  d-appendix h3 {
    grid-column: page-start / text-start;
    font-size: 15px;
    font-weight: 500;
    margin-top: 1em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.65);
  }

  d-appendix h3 + * {
    margin-top: 1em;
  }

  d-appendix ol {
    padding: 0 0 0 15px;
  }

  @media (min-width: 768px) {
    d-appendix ol {
      padding: 0 0 0 30px;
      margin-left: -30px;
    }
  }

  d-appendix li {
    margin-bottom: 1em;
  }

  d-appendix a {
    color: rgba(0, 0, 0, 0.6);
  }

  d-appendix > * {
    grid-column: text;
  }

  d-appendix > d-footnote-list,
  d-appendix > d-citation-list,
  d-appendix > distill-appendix {
    grid-column: screen;
  }

  /* Include footnote styles here so they can be overridden */

  d-footnote-list {
    contain: layout style;
  }

  d-footnote-list > * {
    grid-column: text;
  }

  d-footnote-list a.footnote-backlink {
    color: rgba(0,0,0,0.3);
    padding-left: 0.5em;
  }



  /* Anchor.js */

  .anchorjs-link {
    /*transition: all .25s linear; */
    text-decoration: none;
    border-bottom: none;
  }
  *:hover > .anchorjs-link {
    margin-left: -1.125em !important;
    text-decoration: none;
    border-bottom: none;
  }

  /* Social footer */

  .social_footer {
    margin-top: 30px;
    margin-bottom: 0;
    color: rgba(0,0,0,0.67);
  }

  .disqus-comments {
    margin-right: 30px;
  }

  .disqus-comment-count {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
    cursor: pointer;
  }

  #disqus_thread {
    margin-top: 30px;
  }

  .article-sharing a {
    border-bottom: none;
    margin-right: 8px;
  }

  .article-sharing a:hover {
    border-bottom: none;
  }

  .sidebar-section.subscribe {
    font-size: 12px;
    line-height: 1.6em;
  }

  .subscribe p {
    margin-bottom: 0.5em;
  }


  .article-footer .subscribe {
    font-size: 15px;
    margin-top: 45px;
  }


  .sidebar-section.custom {
    font-size: 12px;
    line-height: 1.6em;
  }

  .custom p {
    margin-bottom: 0.5em;
  }

  /* Styles for listing layout (hide title) */
  .layout-listing d-title, .layout-listing .d-title {
    display: none;
  }

  /* Styles for posts lists (not auto-injected) */


  .posts-with-sidebar {
    padding-left: 45px;
    padding-right: 45px;
  }

  .posts-list .description h2,
  .posts-list .description p {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  }

  .posts-list .description h2 {
    font-weight: 700;
    border-bottom: none;
    padding-bottom: 0;
  }

  .posts-list h2.post-tag {
    border-bottom: 1px solid rgba(0, 0, 0, 0.2);
    padding-bottom: 12px;
  }
  .posts-list {
    margin-top: 60px;
    margin-bottom: 24px;
  }

  .posts-list .post-preview {
    text-decoration: none;
    overflow: hidden;
    display: block;
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
    padding: 24px 0;
  }

  .post-preview-last {
    border-bottom: none !important;
  }

  .posts-list .posts-list-caption {
    grid-column: screen;
    font-weight: 400;
  }

  .posts-list .post-preview h2 {
    margin: 0 0 6px 0;
    line-height: 1.2em;
    font-style: normal;
    font-size: 24px;
  }

  .posts-list .post-preview p {
    margin: 0 0 12px 0;
    line-height: 1.4em;
    font-size: 16px;
  }

  .posts-list .post-preview .thumbnail {
    box-sizing: border-box;
    margin-bottom: 24px;
    position: relative;
    max-width: 500px;
  }
  .posts-list .post-preview img {
    width: 100%;
    display: block;
  }

  .posts-list .metadata {
    font-size: 12px;
    line-height: 1.4em;
    margin-bottom: 18px;
  }

  .posts-list .metadata > * {
    display: inline-block;
  }

  .posts-list .metadata .publishedDate {
    margin-right: 2em;
  }

  .posts-list .metadata .dt-authors {
    display: block;
    margin-top: 0.3em;
    margin-right: 2em;
  }

  .posts-list .dt-tags {
    display: block;
    line-height: 1em;
  }

  .posts-list .dt-tags .dt-tag {
    display: inline-block;
    color: rgba(0,0,0,0.6);
    padding: 0.3em 0.4em;
    margin-right: 0.2em;
    margin-bottom: 0.4em;
    font-size: 60%;
    border: 1px solid rgba(0,0,0,0.2);
    border-radius: 3px;
    text-transform: uppercase;
    font-weight: 500;
  }

  .posts-list img {
    opacity: 1;
  }

  .posts-list img[data-src] {
    opacity: 0;
  }

  .posts-more {
    clear: both;
  }


  .posts-sidebar {
    font-size: 16px;
  }

  .posts-sidebar h3 {
    font-size: 16px;
    margin-top: 0;
    margin-bottom: 0.5em;
    font-weight: 400;
    text-transform: uppercase;
  }

  .sidebar-section {
    margin-bottom: 30px;
  }

  .categories ul {
    list-style-type: none;
    margin: 0;
    padding: 0;
  }

  .categories li {
    color: rgba(0, 0, 0, 0.8);
    margin-bottom: 0;
  }

  .categories li>a {
    border-bottom: none;
  }

  .categories li>a:hover {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  }

  .categories .active {
    font-weight: 600;
  }

  .categories .category-count {
    color: rgba(0, 0, 0, 0.4);
  }


  @media(min-width: 768px) {
    .posts-list .post-preview h2 {
      font-size: 26px;
    }
    .posts-list .post-preview .thumbnail {
      float: right;
      width: 30%;
      margin-bottom: 0;
    }
    .posts-list .post-preview .description {
      float: left;
      width: 45%;
    }
    .posts-list .post-preview .metadata {
      float: left;
      width: 20%;
      margin-top: 8px;
    }
    .posts-list .post-preview p {
      margin: 0 0 12px 0;
      line-height: 1.5em;
      font-size: 16px;
    }
    .posts-with-sidebar .posts-list {
      float: left;
      width: 75%;
    }
    .posts-with-sidebar .posts-sidebar {
      float: right;
      width: 20%;
      margin-top: 60px;
      padding-top: 24px;
      padding-bottom: 24px;
    }
  }


  /* Improve display for browsers without grid (IE/Edge <= 15) */

  .downlevel {
    line-height: 1.6em;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    margin: 0;
  }

  .downlevel .d-title {
    padding-top: 6rem;
    padding-bottom: 1.5rem;
  }

  .downlevel .d-title h1 {
    font-size: 50px;
    font-weight: 700;
    line-height: 1.1em;
    margin: 0 0 0.5rem;
  }

  .downlevel .d-title p {
    font-weight: 300;
    font-size: 1.2rem;
    line-height: 1.55em;
    margin-top: 0;
  }

  .downlevel .d-byline {
    padding-top: 0.8em;
    padding-bottom: 0.8em;
    font-size: 0.8rem;
    line-height: 1.8em;
  }

  .downlevel .section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
  }

  .downlevel .d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
    padding-top: 1rem;
    padding-bottom: 2rem;
  }


  .downlevel .d-appendix {
    padding-left: 0;
    padding-right: 0;
    max-width: none;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.5);
    padding-top: 40px;
    padding-bottom: 48px;
  }

  .downlevel .footnotes ol {
    padding-left: 13px;
  }

  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
    padding-left: 40px;
    padding-right: 40px;
  }

  @media(min-width: 768px) {
    .downlevel .base-grid,
    .downlevel .distill-header,
    .downlevel .d-title,
    .downlevel .d-abstract,
    .downlevel .d-article,
    .downlevel .d-appendix,
    .downlevel .distill-appendix,
    .downlevel .d-byline,
    .downlevel .d-footnote-list,
    .downlevel .d-citation-list,
    .downlevel .distill-footer,
    .downlevel .appendix-bottom,
    .downlevel .posts-container {
    padding-left: 150px;
    padding-right: 150px;
    max-width: 900px;
  }
  }

  .downlevel pre code {
    display: block;
    border-left: 2px solid rgba(0, 0, 0, .1);
    padding: 0 0 0 20px;
    font-size: 14px;
  }

  .downlevel code, .downlevel pre {
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;

    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;

    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }

  .downlevel .posts-list .post-preview {
    color: inherit;
  }



  </style>

  <script type="application/javascript">

  function is_downlevel_browser() {
    if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                   window.navigator.userAgent)) {
      return true;
    } else {
      return window.load_distill_framework === undefined;
    }
  }

  // show body when load is complete
  function on_load_complete() {

    // add anchors
    if (window.anchors) {
      window.anchors.options.placement = 'left';
      window.anchors.add('d-article > h2, d-article > h3, d-article > h4, d-article > h5');
    }


    // set body to visible
    document.body.style.visibility = 'visible';

    // force redraw for leaflet widgets
    if (window.HTMLWidgets) {
      var maps = window.HTMLWidgets.findAll(".leaflet");
      $.each(maps, function(i, el) {
        var map = this.getMap();
        map.invalidateSize();
        map.eachLayer(function(layer) {
          if (layer instanceof L.TileLayer)
            layer.redraw();
        });
      });
    }

    // trigger 'shown' so htmlwidgets resize
    $('d-article').trigger('shown');
  }

  function init_distill() {

    init_common();

    // create front matter
    var front_matter = $('<d-front-matter></d-front-matter>');
    $('#distill-front-matter').wrap(front_matter);

    // create d-title
    $('.d-title').changeElementType('d-title');

    // create d-byline
    var byline = $('<d-byline></d-byline>');
    $('.d-byline').replaceWith(byline);

    // create d-article
    var article = $('<d-article></d-article>');
    $('.d-article').wrap(article).children().unwrap();

    // move posts container into article
    $('.posts-container').appendTo($('d-article'));

    // create d-appendix
    $('.d-appendix').changeElementType('d-appendix');

    // flag indicating that we have appendix items
    var appendix = $('.appendix-bottom').children('h3').length > 0;

    // replace footnotes with <d-footnote>
    $('.footnote-ref').each(function(i, val) {
      appendix = true;
      var href = $(this).attr('href');
      var id = href.replace('#', '');
      var fn = $('#' + id);
      var fn_p = $('#' + id + '>p');
      fn_p.find('.footnote-back').remove();
      var text = fn_p.html();
      var dtfn = $('<d-footnote></d-footnote>');
      dtfn.html(text);
      $(this).replaceWith(dtfn);
    });
    // remove footnotes
    $('.footnotes').remove();

    // move refs into #references-listing
    $('#references-listing').replaceWith($('#refs'));

    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      var id = $(this).attr('id');
      $('.d-contents a[href="#' + id + '"]').parent().remove();
      appendix = true;
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
    });

    // show d-appendix if we have appendix content
    $("d-appendix").css('display', appendix ? 'grid' : 'none');

    // localize layout chunks to just output
    $('.layout-chunk').each(function(i, val) {

      // capture layout
      var layout = $(this).attr('data-layout');

      // apply layout to markdown level block elements
      var elements = $(this).children().not('details, div.sourceCode, pre, script');
      elements.each(function(i, el) {
        var layout_div = $('<div class="' + layout + '"></div>');
        if (layout_div.hasClass('shaded')) {
          var shaded_content = $('<div class="shaded-content"></div>');
          $(this).wrap(shaded_content);
          $(this).parent().wrap(layout_div);
        } else {
          $(this).wrap(layout_div);
        }
      });


      // unwrap the layout-chunk div
      $(this).children().unwrap();
    });

    // remove code block used to force  highlighting css
    $('.distill-force-highlighting-css').parent().remove();

    // remove empty line numbers inserted by pandoc when using a
    // custom syntax highlighting theme
    $('code.sourceCode a:empty').remove();

    // load distill framework
    load_distill_framework();

    // wait for window.distillRunlevel == 4 to do post processing
    function distill_post_process() {

      if (!window.distillRunlevel || window.distillRunlevel < 4)
        return;

      // hide author/affiliations entirely if we have no authors
      var front_matter = JSON.parse($("#distill-front-matter").html());
      var have_authors = front_matter.authors && front_matter.authors.length > 0;
      if (!have_authors)
        $('d-byline').addClass('hidden');

      // article with toc class
      $('.d-contents').parent().addClass('d-article-with-toc');

      // strip links that point to #
      $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

      // add orcid ids
      $('.authors-affiliations').find('.author').each(function(i, el) {
        var orcid_id = front_matter.authors[i].orcidID;
        if (orcid_id) {
          var a = $('<a></a>');
          a.attr('href', 'https://orcid.org/' + orcid_id);
          var img = $('<img></img>');
          img.addClass('orcid-id');
          img.attr('alt', 'ORCID ID');
          img.attr('src','data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==');
          a.append(img);
          $(this).append(a);
        }
      });

      // hide elements of author/affiliations grid that have no value
      function hide_byline_column(caption) {
        $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
      }

      // affiliations
      var have_affiliations = false;
      for (var i = 0; i<front_matter.authors.length; ++i) {
        var author = front_matter.authors[i];
        if (author.affiliation !== "&nbsp;") {
          have_affiliations = true;
          break;
        }
      }
      if (!have_affiliations)
        $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

      // published date
      if (!front_matter.publishedDate)
        hide_byline_column("Published");

      // document object identifier
      var doi = $('d-byline').find('h3:contains("DOI")');
      var doi_p = doi.next().empty();
      if (!front_matter.doi) {
        // if we have a citation and valid citationText then link to that
        if ($('#citation').length > 0 && front_matter.citationText) {
          doi.html('Citation');
          $('<a href="#citation"></a>')
            .text(front_matter.citationText)
            .appendTo(doi_p);
        } else {
          hide_byline_column("DOI");
        }
      } else {
        $('<a></a>')
           .attr('href', "https://doi.org/" + front_matter.doi)
           .html(front_matter.doi)
           .appendTo(doi_p);
      }

       // change plural form of authors/affiliations
      if (front_matter.authors.length === 1) {
        var grid = $('.authors-affiliations');
        grid.children('h3:contains("Authors")').text('Author');
        grid.children('h3:contains("Affiliations")').text('Affiliation');
      }

      // remove d-appendix and d-footnote-list local styles
      $('d-appendix > style:first-child').remove();
      $('d-footnote-list > style:first-child').remove();

      // move appendix-bottom entries to the bottom
      $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
      $('.appendix-bottom').remove();

      // hoverable references
      $('span.citation[data-cites]').each(function() {
        var refs = $(this).attr('data-cites').split(" ");
        var refHtml = refs.map(function(ref) {
          return "<p>" + $('#ref-' + ref).html() + "</p>";
        }).join("\n");
        window.tippy(this, {
          allowHTML: true,
          content: refHtml,
          maxWidth: 500,
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start'
        });
      });

      // clear polling timer
      clearInterval(tid);

      // show body now that everything is ready
      on_load_complete();
    }

    var tid = setInterval(distill_post_process, 50);
    distill_post_process();

  }

  function init_downlevel() {

    init_common();

     // insert hr after d-title
    $('.d-title').after($('<hr class="section-separator"/>'));

    // check if we have authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;

    // manage byline/border
    if (!have_authors)
      $('.d-byline').remove();
    $('.d-byline').after($('<hr class="section-separator"/>'));
    $('.d-byline a').remove();

    // remove toc
    $('.d-contents').remove();

    // move appendix elements
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
    });


    // inject headers into references and footnotes
    var refs_header = $('<h3></h3>');
    refs_header.text('References');
    $('#refs').prepend(refs_header);

    var footnotes_header = $('<h3></h3');
    footnotes_header.text('Footnotes');
    $('.footnotes').children('hr').first().replaceWith(footnotes_header);

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // remove appendix if it's empty
    if ($('.d-appendix').children().length === 0)
      $('.d-appendix').remove();

    // prepend separator above appendix
    $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

    // trim code
    $('pre>code').each(function(i, val) {
      $(this).html($.trim($(this).html()));
    });

    // move posts-container right before article
    $('.posts-container').insertBefore($('.d-article'));

    $('body').addClass('downlevel');

    on_load_complete();
  }


  function init_common() {

    // jquery plugin to change element types
    (function($) {
      $.fn.changeElementType = function(newType) {
        var attrs = {};

        $.each(this[0].attributes, function(idx, attr) {
          attrs[attr.nodeName] = attr.nodeValue;
        });

        this.replaceWith(function() {
          return $("<" + newType + "/>", attrs).append($(this).contents());
        });
      };
    })(jQuery);

    // prevent underline for linked images
    $('a > img').parent().css({'border-bottom' : 'none'});

    // mark non-body figures created by knitr chunks as 100% width
    $('.layout-chunk').each(function(i, val) {
      var figures = $(this).find('img, .html-widget');
      if ($(this).attr('data-layout') !== "l-body") {
        figures.css('width', '100%');
      } else {
        figures.css('max-width', '100%');
        figures.filter("[width]").each(function(i, val) {
          var fig = $(this);
          fig.css('width', fig.attr('width') + 'px');
        });

      }
    });

    // auto-append index.html to post-preview links in file: protocol
    // and in rstudio ide preview
    $('.post-preview').each(function(i, val) {
      if (window.location.protocol === "file:")
        $(this).attr('href', $(this).attr('href') + "index.html");
    });

    // get rid of index.html references in header
    if (window.location.protocol !== "file:") {
      $('.distill-site-header a[href]').each(function(i,val) {
        $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
      });
    }

    // add class to pandoc style tables
    $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
    $('.kable-table').children('table').addClass('pandoc-table');

    // add figcaption style to table captions
    $('caption').parent('table').addClass("figcaption");

    // initialize posts list
    if (window.init_posts_list)
      window.init_posts_list();

    // implmement disqus comment link
    $('.disqus-comment-count').click(function() {
      window.headroom_prevent_pin = true;
      $('#disqus_thread').toggleClass('hidden');
      if (!$('#disqus_thread').hasClass('hidden')) {
        var offset = $(this).offset();
        $(window).resize();
        $('html, body').animate({
          scrollTop: offset.top - 35
        });
      }
    });
  }

  document.addEventListener('DOMContentLoaded', function() {
    if (is_downlevel_browser())
      init_downlevel();
    else
      window.addEventListener('WebComponentsReady', init_distill);
  });

  </script>

  <style type="text/css">
  /* base variables */

  /* Edit the CSS properties in this file to create a custom
     Distill theme. Only edit values in the right column
     for each row; values shown are the CSS defaults.
     To return any property to the default,
     you may set its value to: unset
     All rows must end with a semi-colon.                      */

  /* Optional: embed custom fonts here with `@import`          */
  /* This must remain at the top of this file.                 */



  html {
    /*-- Main font sizes --*/
    --title-size:      50px;
    --body-size:       1.06rem;
    --code-size:       14px;
    --aside-size:      12px;
    --fig-cap-size:    13px;
    /*-- Main font colors --*/
    --title-color:     #000000;
    --header-color:    rgba(0, 0, 0, 0.8);
    --body-color:      rgba(0, 0, 0, 0.8);
    --aside-color:     rgba(0, 0, 0, 0.6);
    --fig-cap-color:   rgba(0, 0, 0, 0.6);
    /*-- Specify custom fonts ~~~ must be imported above   --*/
    --heading-font:    sans-serif;
    --mono-font:       monospace;
    --body-font:       sans-serif;
    --navbar-font:     sans-serif;  /* websites + blogs only */
  }

  /*-- ARTICLE METADATA --*/
  d-byline {
    --heading-size:    0.6rem;
    --heading-color:   rgba(0, 0, 0, 0.5);
    --body-size:       0.8rem;
    --body-color:      rgba(0, 0, 0, 0.8);
  }

  /*-- ARTICLE TABLE OF CONTENTS --*/
  .d-contents {
    --heading-size:    18px;
    --contents-size:   13px;
  }

  /*-- ARTICLE APPENDIX --*/
  d-appendix {
    --heading-size:    15px;
    --heading-color:   rgba(0, 0, 0, 0.65);
    --text-size:       0.8em;
    --text-color:      rgba(0, 0, 0, 0.5);
  }

  /*-- WEBSITE HEADER + FOOTER --*/
  /* These properties only apply to Distill sites and blogs  */

  .distill-site-header {
    --title-size:       18px;
    --text-color:       rgba(255, 255, 255, 0.8);
    --text-size:        15px;
    --hover-color:      white;
    --bkgd-color:       #0F2E3D;
  }

  .distill-site-footer {
    --text-color:       rgba(255, 255, 255, 0.8);
    --text-size:        15px;
    --hover-color:      white;
    --bkgd-color:       #0F2E3D;
  }

  /*-- Additional custom styles --*/
  /* Add any additional CSS rules below                      */
  </style>
  <style type="text/css">strong {
    font-weight: 700; /* thicker than default bold */
  }


  /* base variables */

  /* Edit the CSS properties in this file to create a custom
     Distill theme. Only edit values in the right column
     for each row; values shown are the CSS defaults.
     To return any property to the default,
     you may set its value to: unset
     All rows must end with a semi-colon.                      */

  /* Optional: embed custom fonts here with `@import`          */
  /* This must remain at the top of this file.                 */

  /* Header font */
  @import url('https://fonts.googleapis.com/css2?family=Sanchez&display=swap');

  /* Body font */
  @import url('https://fonts.googleapis.com/css2?family=Nunito+Sans:wght@300;400&display=swap');

  /* Code font (Roboto Mono) */
  @import url('https://fonts.googleapis.com/css2?family=Roboto+Mono:wght@300;400&display=swap');

  html {
    /*-- Main font sizes --*/
    --title-size:      50px;
    --title-weight:    400;
    --body-size:       1.06rem;
    --code-size:       14px;
    --aside-size:      12px;
    --fig-cap-size:    13px;
    /*-- Main font colors --*/
    --title-color:     #003660;
    --title-weight:    400;
    --header-color:    rgba(4, 124, 145, 1);
    --body-color:      rgba(0, 0, 0, 0.8);
    --aside-color:     rgba(0, 0, 0, 0.6);
    --fig-cap-color:   rgba(0, 0, 0, 0.6);
    /*-- Specify custom fonts ~~~ must be imported above   --*/
    --heading-font:    Sanchez;
    --mono-font:       Roboto Mono;
    --body-font:       Nunito Sans;
    --navbar-font:     Nunito Sans;  /* websites + blogs only */
  }

  /*-- ARTICLE METADATA --*/
  d-byline {
    --heading-size:    0.6rem;
    --heading-color:   rgba(0, 0, 0, 0.5);
    --body-size:       0.8rem;
    --body-color:      rgba(0, 0, 0, 0.8);
  }

  /*-- ARTICLE TABLE OF CONTENTS --*/
  .d-contents {
    --heading-size:    18px;
    --contents-size:   13px;
  }

  /*-- ARTICLE APPENDIX --*/
  d-appendix {
    --heading-size:    15px;
    --heading-color:   rgba(0, 0, 0, 0.65);
    --text-size:       0.8em;
    --text-color:      rgba(0, 0, 0, 0.5);
  }

  /*-- WEBSITE HEADER + FOOTER --*/
  /* These properties only apply to Distill sites and blogs  */

  .distill-site-header {
    --title-size:       20px;
    --text-color:       rgba(255, 255, 255, 0.8);
    --text-size:        18px;
    --hover-color:      white;
    --bkgd-color:       #047C91;
  }

  .distill-site-footer {
    --text-color:       rgba(255, 255, 255, 0.8);
    --text-size:        15px;
    --hover-color:      white;
    --bkgd-color:       #003660;
  }

  /*-- Additional custom styles --*/
  /* Add any additional CSS rules below                      */

  d-article h2 {
      grid-column: text;
      font-size: 32px;
      font-weight: 300;
      line-height: 1.1em;
      margin: 0 0 0.5rem;
      padding-top: 20px;
  }

  d-article h3 {
      grid-column: text;
      font-size: 24px;
      font-weight: 300;
      line-height: 1.1em;
      margin: 0 0 0.5rem;
  }

  a.title {
    font-style: bold;
  }

  a, .nav-dropdown .nav-dropbtn {
    font-weight: 500;
  }

  /* Set colors for headers */
  d-article h1, d-article h2, d-article h3, d-article h4, d-article h5, d-article h6 {
      color: rgba(4, 124, 145, 0.8);
  }

  /* Formatting tables (can update here or individually) */
  table, td, tr, th {
    border-collapse: collapse;
    font-family: Nunito Sans;
    border: 1px solid gainsboro;
    vertical-align: top;
  }

  d-article table th, d-article table td {
      font-size: 15px;
      padding: 2px 8px;
      border: 1px solid gainsboro;
  }

  /* Code style formatting of text */
  code {
    font-family: Roboto Mono;
  }

  .distill-site-header a, .distill-site-header .title {
      text-align: left;
      padding: 14px 14px 14px 14px;
  }

  d-title h1 {
      grid-column: text;
      font-size: 40px;
      font-weight: 400;
      line-height: 1.1em;
      margin: 0 0 0.5rem;
  }

  /* Update toc list font */
  .d-contents nav ul li {
      font-size: 20px;
  }

  /* Update overall layout (body width) */
  @media(min-width: 1180px) {
      .base-grid,
      distill-header,
      d-title,
      d-abstract,
      d-article,
      d-appendix,
      distill-appendix,
      d-byline,
      d-footnote-list,
      d-citation-list,
      distill-footer {
        grid-template-columns: [screen-start] 0.5fr [page-start kicker-start] 30px [middle-start] 50px [text-start kicker-end] 90px 90px 90px 90px 90px 90px 90px 90px [text-end gutter-start] 30px [middle-end] 50px [page-end gutter-end] 0.5fr [screen-end];
        grid-column-gap: 20px;
      }

  /* Change navbar dropdown menu bg color */
  .nav-dropdown-content a:hover {
      background-color: #003660;
      color: black;
  }
  </style>
  <style type="text/css">
  /* base style */

  /* FONT FAMILIES */

  :root {
    --heading-default: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    --mono-default: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    --body-default: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  }

  body,
  .posts-list .post-preview p,
  .posts-list .description p {
    font-family: var(--body-font), var(--body-default);
  }

  h1, h2, h3, h4, h5, h6,
  .posts-list .post-preview h2,
  .posts-list .description h2 {
    font-family: var(--heading-font), var(--heading-default);
  }

  d-article div.sourceCode code,
  d-article pre code {
    font-family: var(--mono-font), var(--mono-default);
  }


  /*-- TITLE --*/
  d-title h1,
  .posts-list > h1 {
    color: var(--title-color, black);
  }

  d-title h1 {
    font-size: var(--title-size, 50px);
  }

  /*-- HEADERS --*/
  d-article h1,
  d-article h2,
  d-article h3,
  d-article h4,
  d-article h5,
  d-article h6 {
    color: var(--header-color, rgba(0, 0, 0, 0.8));
  }

  /*-- BODY --*/
  d-article > p,  /* only text inside of <p> tags */
  d-article > ul, /* lists */
  d-article > ol {
    color: var(--body-color, rgba(0, 0, 0, 0.8));
    font-size: var(--body-size, 1.06rem);
  }


  /*-- CODE --*/
  d-article div.sourceCode code,
  d-article pre code {
    font-size: var(--code-size, 14px);
  }

  /*-- ASIDE --*/
  d-article aside {
    font-size: var(--aside-size, 12px);
    color: var(--aside-color, rgba(0, 0, 0, 0.6));
  }

  /*-- FIGURE CAPTIONS --*/
  figure .caption,
  figure figcaption,
  .figure .caption {
    font-size: var(--fig-cap-size, 13px);
    color: var(--fig-cap-color, rgba(0, 0, 0, 0.6));
  }

  /*-- METADATA --*/
  d-byline h3 {
    font-size: var(--heading-size, 0.6rem);
    color: var(--heading-color, rgba(0, 0, 0, 0.5));
  }

  d-byline {
    font-size: var(--body-size, 0.8rem);
    color: var(--body-color, rgba(0, 0, 0, 0.8));
  }

  d-byline a,
  d-article d-byline a {
    color: var(--body-color, rgba(0, 0, 0, 0.8));
  }

  /*-- TABLE OF CONTENTS --*/
  .d-contents nav h3 {
    font-size: var(--heading-size, 18px);
  }

  .d-contents nav a {
    font-size: var(--contents-size, 13px);
  }

  /*-- APPENDIX --*/
  d-appendix h3 {
    font-size: var(--heading-size, 15px);
    color: var(--heading-color, rgba(0, 0, 0, 0.65));
  }

  d-appendix {
    font-size: var(--text-size, 0.8em);
    color: var(--text-color, rgba(0, 0, 0, 0.5));
  }

  d-appendix d-footnote-list a.footnote-backlink {
    color: var(--text-color, rgba(0, 0, 0, 0.5));
  }

  /*-- WEBSITE HEADER + FOOTER --*/
  .distill-site-header .title {
    font-size: var(--title-size, 18px);
    font-family: var(--navbar-font), var(--heading-default);
  }

  .distill-site-header a,
  .nav-dropdown .nav-dropbtn {
    font-family: var(--navbar-font), var(--heading-default);
  }

  .nav-dropdown .nav-dropbtn {
    color: var(--text-color, rgba(255, 255, 255, 0.8));
    font-size: var(--text-size, 15px);
  }

  .distill-site-header a:hover,
  .nav-dropdown:hover .nav-dropbtn {
    color: var(--hover-color, white);
  }

  .distill-site-header {
    font-size: var(--text-size, 15px);
    color: var(--text-color, rgba(255, 255, 255, 0.8));
    background-color: var(--bkgd-color, #0F2E3D);
  }

  .distill-site-footer {
    font-size: var(--text-size, 15px);
    color: var(--text-color, rgba(255, 255, 255, 0.8));
    background-color: var(--bkgd-color, #0F2E3D);
  }

  .distill-site-footer a:hover {
    color: var(--hover-color, white);
  }</style>
  <!--/radix_placeholder_distill-->
  <script src="site_libs/header-attrs-2.11/header-attrs.js"></script>
  <script src="site_libs/popper-2.6.0/popper.min.js"></script>
  <link href="site_libs/tippy-6.2.7/tippy.css" rel="stylesheet" />
  <link href="site_libs/tippy-6.2.7/tippy-light-border.css" rel="stylesheet" />
  <script src="site_libs/tippy-6.2.7/tippy.umd.min.js"></script>
  <script src="site_libs/anchor-4.2.2/anchor.min.js"></script>
  <script src="site_libs/bowser-1.9.3/bowser.min.js"></script>
  <script src="site_libs/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="site_libs/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
  <!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"lab4c_5.3-using-a-pretrained-convnet","authors":[]}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<header class="header header--fixed" role="banner">
<nav class="distill-site-nav distill-site-header">
<div class="nav-left">
<a href="index.html" class="title">EDS 232</a>
</div>
<div class="nav-right">
<div class="nav-dropdown">
<button class="nav-dropbtn">
Labs
 
<span class="down-arrow">&#x25BE;</span>
</button>
<div class="nav-dropdown-content">
<a href="lab1a_sdm-explore.html">1a. Species: explore</a>
<a href="lab1b_sdm-regress.html">1b. Species: regress</a>
<a href="lab1c_sdm-trees.html">1c. Species: trees</a>
<a href="lab1d_sdm-evaluate.html">1d. Species: evaluate</a>
<a href="lab2a_community-cluster.html">2a. Community: cluster</a>
<a href="lab2b_community-ordination.html">2b. Community: ordination</a>
<a href="lab3_reserves.html">3. Reserve Design: prioritize</a>
<a href="review_midterm.html">Mid-Term Review</a>
<a href="lab4a_dl-neural-nets.html">4a. Deep Learning: neural networks</a>
<a href="lab4b_examples.html">4b. Deep Learning: keras</a>
<a href="gp_kaggle.html">Group Project: Kaggle Competition</a>
</div>
</div>
<a href="glossary.html">Glosssary</a>
<a href="resources.html">Resources</a>
<a href="https://github.com/bbest/eds232-ml">
<i class="fab fa-github" aria-hidden="true"></i>
</a>
<a href="javascript:void(0);" class="nav-toggle">&#9776;</a>
</div>
</nav>
</header>
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>lab4c_5.3-using-a-pretrained-convnet</h1>
<!--radix_placeholder_categories-->
<!--/radix_placeholder_categories-->

</div>


<div class="d-article">
<div class="d-contents d-contents-float">
<nav class="l-text toc figcaption" id="TOC">
<h3>Contents</h3>
<ul>
<li><a href="#feature-extraction"><span class="toc-section-number">0.1</span> Feature extraction</a></li>
<li><a href="#fine-tuning"><span class="toc-section-number">0.2</span> Fine-tuning</a></li>
<li><a href="#take-aways-using-convnets-with-small-datasets"><span class="toc-section-number">0.3</span> Take-aways: using convnets with small datasets</a></li>
</ul>
</nav>
</div>
<hr />
<p>This notebook contains the code samples found in Chapter 5, Section 3 of <a href="https://www.manning.com/books/deep-learning-with-r">Deep Learning with R</a>. Note that the original text features far more content, in particular further explanations and figures: in this notebook, you will only find source code and related comments.</p>
<hr />
<p>A common and highly effective approach to deep learning on small image datasets is to leverage a pre-trained network. A pre-trained network is simply a saved network previously trained on a large dataset, typically on a large-scale image classification task. If this original dataset is large enough and general enough, then the spatial feature hierarchy learned by the pre-trained network can effectively act as a generic model of our visual world, and hence its features can prove useful for many different computer vision problems, even though these new problems might involve completely different classes from those of the original task. For instance, one might train a network on ImageNet (where classes are mostly animals and everyday objects) and then re-purpose this trained network for something as remote as identifying furniture items in images. Such portability of learned features across different problems is a key advantage of deep learning compared to many older shallow learning approaches, and it makes deep learning very effective for small-data problems.</p>
<p>In our case, we will consider a large convnet trained on the ImageNet dataset (1.4 million labeled images and 1000 different classes). ImageNet contains many animal classes, including different species of cats and dogs, and we can thus expect to perform very well on our cat vs.dog classification problem.</p>
<p>We will use the VGG16 architecture, developed by Karen Simonyan and Andrew Zisserman in 2014, a simple and widely used convnet architecture for ImageNet. Although it is a bit of an older model, far from the current state of the art and somewhat heavier than many other recent models, we chose it because its architecture is similar to what you are already familiar with, and easy to understand without introducing any new concepts. This may be your first encounter with one of these cutesie model names  VGG, ResNet, Inception, Inception-ResNet, Xception you will get used to them, as they will come up frequently if you keep doing deep learning for computer vision.</p>
<p>There are two ways to leverage a pre-trained network: <em>feature extraction</em> and <em>fine-tuning</em>. We will cover both of them. Lets start with feature extraction.</p>
<h2 data-number="0.1" id="feature-extraction"><span class="header-section-number">0.1</span> Feature extraction</h2>
<p>Feature extraction consists of using the representations learned by a previous network to extract interesting features from new samples. These features are then run through a new classifier, which is trained from scratch.</p>
<p>As we saw previously, convnets used for image classification comprise two parts: they start with a series of pooling and convolution layers, and they end with a densely-connected classifier. The first part is called the convolutional base of the model. In the case of convnets, feature extraction will simply consist of taking the convolutional base of a previously-trained network, running the new data through it, and training a new classifier on top of the output.</p>
<figure>
<img src="https://s3.amazonaws.com/book.keras.io/img/ch5/swapping_fc_classifier.png" alt="swapping FC classifiers" /><figcaption aria-hidden="true">swapping FC classifiers</figcaption>
</figure>
<p>Why only reuse the convolutional base? Could we reuse the densely-connected classifier as well? In general, it should be avoided. The reason is simply that the representations learned by the convolutional base are likely to be more generic and therefore more reusable: the feature maps of a convnet are presence maps of generic concepts over a picture, which is likely to be useful regardless of the computer vision problem at hand. On the other end, the representations learned by the classifier will necessarily be very specific to the set of classes that the model was trained on  they will only contain information about the presence probability of this or that class in the entire picture. Additionally, representations found in densely-connected layers no longer contain any information about <em>where</em> objects are located in the input image: these layers get rid of the notion of space, whereas the object location is still described by convolutional feature maps. For problems where object location matters, densely-connected features would be largely useless.</p>
<p>Note that the level of generality (and therefore reusability) of the representations extracted by specific convolution layers depends on the depth of the layer in the model. Layers that come earlier in the model extract local, highly generic feature maps (such as visual edges, colors, and textures), while layers higher-up extract more abstract concepts (such as cat ear or dog eye). So if your new dataset differs a lot from the dataset that the original model was trained on, you may be better off using only the first few layers of the model to do feature extraction, rather than using the entire convolutional base.</p>
<p>In our case, since the ImageNet class set did contain multiple dog and cat classes, it is likely that it would be beneficial to reuse the information contained in the densely-connected layers of the original model. However, we will chose not to, in order to cover the more general case where the class set of the new problem does not overlap with the class set of the original model.</p>
<p>Lets put this in practice by using the convolutional base of the VGG16 network, trained on ImageNet, to extract interesting features from our cat and dog images, and then training a cat vs.dog classifier on top of these features.</p>
<p>The VGG16 model, among others, comes prepackaged with Keras. Heres the list of image-classification models (all pretrained on the ImageNet dataset) that are available as part of Keras:</p>
<ul>
<li>Xception</li>
<li>InceptionV3</li>
<li>ResNet50</li>
<li>VGG16</li>
<li>VGG19</li>
<li>MobileNet</li>
</ul>
<p>Lets instantiate the VGG16 model:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://keras.rstudio.com'>keras</a></span><span class='op'>)</span>

<span class='va'>conv_base</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://keras.rstudio.com/reference/application_vgg.html'>application_vgg16</a></span><span class='op'>(</span>
  weights <span class='op'>=</span> <span class='st'>"imagenet"</span>,
  include_top <span class='op'>=</span> <span class='cn'>FALSE</span>,
  input_shape <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>150</span>, <span class='fl'>150</span>, <span class='fl'>3</span><span class='op'>)</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>We passed three arguments to the constructor:</p>
<ul>
<li><code>weights</code>, to specify which weight checkpoint to initialize the model from</li>
<li><code>include_top</code>, which refers to including or not the densely-connected classifier on top of the network. By default, this densely-connected classifier would correspond to the 1000 classes from ImageNet. Since we intend to use our own densely-connected classifier (with only two classes, cat and dog), we dont need to include it.</li>
<li><code>input_shape</code>, the shape of the image tensors that we will feed to the network. This argument is purely optional: if we dont pass it, then the network will be able to process inputs of any size.</li>
</ul>
<p>Heres the detail of the architecture of the VGG16 convolutional base: its very similar to the simple convnets that you are already familiar with.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/summary.html'>summary</a></span><span class='op'>(</span><span class='va'>conv_base</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>Model: &quot;vgg16&quot;
______________________________________________________________________
 Layer (type)                  Output Shape                Param #    
======================================================================
 input_1 (InputLayer)          [(None, 150, 150, 3)]       0          
                                                                      
 block1_conv1 (Conv2D)         (None, 150, 150, 64)        1792       
                                                                      
 block1_conv2 (Conv2D)         (None, 150, 150, 64)        36928      
                                                                      
 block1_pool (MaxPooling2D)    (None, 75, 75, 64)          0          
                                                                      
 block2_conv1 (Conv2D)         (None, 75, 75, 128)         73856      
                                                                      
 block2_conv2 (Conv2D)         (None, 75, 75, 128)         147584     
                                                                      
 block2_pool (MaxPooling2D)    (None, 37, 37, 128)         0          
                                                                      
 block3_conv1 (Conv2D)         (None, 37, 37, 256)         295168     
                                                                      
 block3_conv2 (Conv2D)         (None, 37, 37, 256)         590080     
                                                                      
 block3_conv3 (Conv2D)         (None, 37, 37, 256)         590080     
                                                                      
 block3_pool (MaxPooling2D)    (None, 18, 18, 256)         0          
                                                                      
 block4_conv1 (Conv2D)         (None, 18, 18, 512)         1180160    
                                                                      
 block4_conv2 (Conv2D)         (None, 18, 18, 512)         2359808    
                                                                      
 block4_conv3 (Conv2D)         (None, 18, 18, 512)         2359808    
                                                                      
 block4_pool (MaxPooling2D)    (None, 9, 9, 512)           0          
                                                                      
 block5_conv1 (Conv2D)         (None, 9, 9, 512)           2359808    
                                                                      
 block5_conv2 (Conv2D)         (None, 9, 9, 512)           2359808    
                                                                      
 block5_conv3 (Conv2D)         (None, 9, 9, 512)           2359808    
                                                                      
 block5_pool (MaxPooling2D)    (None, 4, 4, 512)           0          
                                                                      
======================================================================
Total params: 14,714,688
Trainable params: 14,714,688
Non-trainable params: 0
______________________________________________________________________</code></pre>
</div>
<p>The final feature map has shape <code>(4, 4, 512)</code>. Thats the feature on top of which we will stick a densely-connected classifier.</p>
<p>At this point, there are two ways you could proceed:</p>
<ul>
<li>Running the convolutional base over your dataset, recording its output to an array on disk, and then using this data as input to a standalone, densely connected classifier similar to those you saw in part 1 of this book. This solution is fast and cheap to run, because it only requires running the convolutional base once for every input image, and the convolutional base is by far the most expensive part of the pipeline. But for the same reason, this technique wont allow you to use data augmentation.</li>
<li>Extending the model you have (<code>conv_base</code>) by adding dense layers on top, and running the whole thing end to end on the input data. This willallow you to use data augmentation, because every input image goes through the convolutional base every time its seen by the model. But for the same reason, this technique is far more expensive than the first.</li>
</ul>
<p>Well cover both techniques. Lets walk through the code required to set up the first one: recording the output of <code>conv_base</code> on your data and using these outputs as inputs to a new model.</p>
<p>Well start by running instances of the previously introduced <code>image_data_generator()</code> to extract images as arrays as well as their labels. We will extract features from these images by calling the <code>predict</code> method on the model.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>base_dir</span>       <span class='op'>&lt;-</span> <span class='st'>"/courses/EDS232/dogs-vs-cats/small"</span>
<span class='va'>train_dir</span>      <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/file.path.html'>file.path</a></span><span class='op'>(</span><span class='va'>base_dir</span>, <span class='st'>"train"</span><span class='op'>)</span>
<span class='va'>validation_dir</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/file.path.html'>file.path</a></span><span class='op'>(</span><span class='va'>base_dir</span>, <span class='st'>"validation"</span><span class='op'>)</span>
<span class='va'>test_dir</span>       <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/file.path.html'>file.path</a></span><span class='op'>(</span><span class='va'>base_dir</span>, <span class='st'>"test"</span><span class='op'>)</span>
<span class='va'>dir_models</span>     <span class='op'>&lt;-</span> <span class='fu'>here</span><span class='fu'>::</span><span class='fu'><a href='https://here.r-lib.org//reference/here.html'>here</a></span><span class='op'>(</span><span class='st'>"data/dl"</span><span class='op'>)</span>

<span class='va'>datagen</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://keras.rstudio.com/reference/image_data_generator.html'>image_data_generator</a></span><span class='op'>(</span>rescale <span class='op'>=</span> <span class='fl'>1</span><span class='op'>/</span><span class='fl'>255</span><span class='op'>)</span>
<span class='va'>batch_size</span> <span class='op'>&lt;-</span> <span class='fl'>20</span>

<span class='va'>extract_features</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>directory</span>, <span class='va'>sample_count</span><span class='op'>)</span> <span class='op'>{</span>
  
  <span class='va'>features</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/array.html'>array</a></span><span class='op'>(</span><span class='fl'>0</span>, dim <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>sample_count</span>, <span class='fl'>4</span>, <span class='fl'>4</span>, <span class='fl'>512</span><span class='op'>)</span><span class='op'>)</span>  
  <span class='va'>labels</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/array.html'>array</a></span><span class='op'>(</span><span class='fl'>0</span>, dim <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>sample_count</span><span class='op'>)</span><span class='op'>)</span>
  
  <span class='va'>generator</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://keras.rstudio.com/reference/flow_images_from_directory.html'>flow_images_from_directory</a></span><span class='op'>(</span>
    directory <span class='op'>=</span> <span class='va'>directory</span>,
    generator <span class='op'>=</span> <span class='va'>datagen</span>,
    target_size <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>150</span>, <span class='fl'>150</span><span class='op'>)</span>,
    batch_size <span class='op'>=</span> <span class='va'>batch_size</span>,
    class_mode <span class='op'>=</span> <span class='st'>"binary"</span>
  <span class='op'>)</span>
  
  <span class='va'>i</span> <span class='op'>&lt;-</span> <span class='fl'>0</span>
  <span class='kw'>while</span><span class='op'>(</span><span class='cn'>TRUE</span><span class='op'>)</span> <span class='op'>{</span>
    <span class='va'>batch</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://keras.rstudio.com/reference/generator_next.html'>generator_next</a></span><span class='op'>(</span><span class='va'>generator</span><span class='op'>)</span>
    <span class='va'>inputs_batch</span> <span class='op'>&lt;-</span> <span class='va'>batch</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span>
    <span class='va'>labels_batch</span> <span class='op'>&lt;-</span> <span class='va'>batch</span><span class='op'>[[</span><span class='fl'>2</span><span class='op'>]</span><span class='op'>]</span>
    <span class='va'>features_batch</span> <span class='op'>&lt;-</span> <span class='va'>conv_base</span> <span class='op'><a href='https://keras.rstudio.com/reference/pipe.html'>%&gt;%</a></span> <span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span><span class='op'>(</span><span class='va'>inputs_batch</span><span class='op'>)</span>
    
    <span class='va'>index_range</span> <span class='op'>&lt;-</span> <span class='op'>(</span><span class='op'>(</span><span class='va'>i</span> <span class='op'>*</span> <span class='va'>batch_size</span><span class='op'>)</span><span class='op'>+</span><span class='fl'>1</span><span class='op'>)</span><span class='op'>:</span><span class='op'>(</span><span class='op'>(</span><span class='va'>i</span> <span class='op'>+</span> <span class='fl'>1</span><span class='op'>)</span> <span class='op'>*</span> <span class='va'>batch_size</span><span class='op'>)</span>
    <span class='va'>features</span><span class='op'>[</span><span class='va'>index_range</span>,,,<span class='op'>]</span> <span class='op'>&lt;-</span> <span class='va'>features_batch</span>
    <span class='va'>labels</span><span class='op'>[</span><span class='va'>index_range</span><span class='op'>]</span> <span class='op'>&lt;-</span> <span class='va'>labels_batch</span>
    
    <span class='va'>i</span> <span class='op'>&lt;-</span> <span class='va'>i</span> <span class='op'>+</span> <span class='fl'>1</span>
    <span class='kw'>if</span> <span class='op'>(</span><span class='va'>i</span> <span class='op'>*</span> <span class='va'>batch_size</span> <span class='op'>&gt;=</span> <span class='va'>sample_count</span><span class='op'>)</span>
      <span class='co'># Note that because generators yield data indefinitely in a loop, </span>
      <span class='co'># you must break after every image has been seen once.</span>
      <span class='kw'>break</span>
  <span class='op'>}</span>
  
  <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span>
    features <span class='op'>=</span> <span class='va'>features</span>, 
    labels <span class='op'>=</span> <span class='va'>labels</span>
  <span class='op'>)</span>
<span class='op'>}</span>

<span class='va'>train</span>      <span class='op'>&lt;-</span> <span class='fu'>extract_features</span><span class='op'>(</span><span class='va'>train_dir</span>,      <span class='fl'>2000</span><span class='op'>)</span>
<span class='va'>validation</span> <span class='op'>&lt;-</span> <span class='fu'>extract_features</span><span class='op'>(</span><span class='va'>validation_dir</span>, <span class='fl'>1000</span><span class='op'>)</span>
<span class='va'>test</span>       <span class='op'>&lt;-</span> <span class='fu'>extract_features</span><span class='op'>(</span><span class='va'>test_dir</span>,       <span class='fl'>1000</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>The extracted features are currently of shape <code>(samples, 4, 4, 512)</code>. We will feed them to a densely-connected classifier, so first we must flatten them to <code>(samples, 8192)</code>:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>reshape_features</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>features</span><span class='op'>)</span> <span class='op'>{</span>
  <span class='fu'><a href='https://rstudio.github.io/reticulate/reference/array_reshape.html'>array_reshape</a></span><span class='op'>(</span><span class='va'>features</span>, dim <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>features</span><span class='op'>)</span>, <span class='fl'>4</span> <span class='op'>*</span> <span class='fl'>4</span> <span class='op'>*</span> <span class='fl'>512</span><span class='op'>)</span><span class='op'>)</span>
<span class='op'>}</span>
<span class='va'>train</span><span class='op'>$</span><span class='va'>features</span>      <span class='op'>&lt;-</span> <span class='fu'>reshape_features</span><span class='op'>(</span><span class='va'>train</span><span class='op'>$</span><span class='va'>features</span><span class='op'>)</span>
<span class='va'>validation</span><span class='op'>$</span><span class='va'>features</span> <span class='op'>&lt;-</span> <span class='fu'>reshape_features</span><span class='op'>(</span><span class='va'>validation</span><span class='op'>$</span><span class='va'>features</span><span class='op'>)</span>
<span class='va'>test</span><span class='op'>$</span><span class='va'>features</span>       <span class='op'>&lt;-</span> <span class='fu'>reshape_features</span><span class='op'>(</span><span class='va'>test</span><span class='op'>$</span><span class='va'>features</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>At this point, we can define our densely-connected classifier (note the use of dropout for regularization), and train it on the data and labels that we just recorded:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>model</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://keras.rstudio.com/reference/keras_model_sequential.html'>keras_model_sequential</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'><a href='https://keras.rstudio.com/reference/pipe.html'>%&gt;%</a></span> 
  <span class='fu'><a href='https://keras.rstudio.com/reference/layer_dense.html'>layer_dense</a></span><span class='op'>(</span>units <span class='op'>=</span> <span class='fl'>256</span>, activation <span class='op'>=</span> <span class='st'>"relu"</span>, 
              input_shape <span class='op'>=</span> <span class='fl'>4</span> <span class='op'>*</span> <span class='fl'>4</span> <span class='op'>*</span> <span class='fl'>512</span><span class='op'>)</span> <span class='op'><a href='https://keras.rstudio.com/reference/pipe.html'>%&gt;%</a></span> 
  <span class='fu'><a href='https://keras.rstudio.com/reference/layer_dropout.html'>layer_dropout</a></span><span class='op'>(</span>rate <span class='op'>=</span> <span class='fl'>0.5</span><span class='op'>)</span> <span class='op'><a href='https://keras.rstudio.com/reference/pipe.html'>%&gt;%</a></span> 
  <span class='fu'><a href='https://keras.rstudio.com/reference/layer_dense.html'>layer_dense</a></span><span class='op'>(</span>units <span class='op'>=</span> <span class='fl'>1</span>, activation <span class='op'>=</span> <span class='st'>"sigmoid"</span><span class='op'>)</span>

<span class='va'>model</span> <span class='op'><a href='https://keras.rstudio.com/reference/pipe.html'>%&gt;%</a></span> <span class='fu'><a href='https://generics.r-lib.org/reference/compile.html'>compile</a></span><span class='op'>(</span>
  optimizer <span class='op'>=</span> <span class='fu'><a href='https://keras.rstudio.com/reference/optimizer_rmsprop.html'>optimizer_rmsprop</a></span><span class='op'>(</span>learning_rate <span class='op'>=</span> <span class='fl'>2e-5</span><span class='op'>)</span>,
  loss <span class='op'>=</span> <span class='st'>"binary_crossentropy"</span>,
  metrics <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>"accuracy"</span><span class='op'>)</span><span class='op'>)</span>

<span class='va'>history</span> <span class='op'>&lt;-</span> <span class='va'>model</span> <span class='op'><a href='https://keras.rstudio.com/reference/pipe.html'>%&gt;%</a></span> <span class='fu'><a href='https://generics.r-lib.org/reference/fit.html'>fit</a></span><span class='op'>(</span>
  <span class='va'>train</span><span class='op'>$</span><span class='va'>features</span>, <span class='va'>train</span><span class='op'>$</span><span class='va'>labels</span>,
  epochs <span class='op'>=</span> <span class='fl'>30</span>,
  batch_size <span class='op'>=</span> <span class='fl'>20</span>,
  validation_data <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='va'>validation</span><span class='op'>$</span><span class='va'>features</span>, <span class='va'>validation</span><span class='op'>$</span><span class='va'>labels</span><span class='op'>)</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>Training is very fast, since we only have to deal with two <code>Dense</code> layers  an epoch takes less than one second even on CPU.</p>
<p>Lets take a look at the loss and accuracy curves during training:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='va'>history</span><span class='op'>)</span>
</code></pre>
</div>
<p><img src="lab4c_5.3-using-a-pretrained-convnet_files/figure-html5/unnamed-chunk-6-1.png" width="624" /></p>
</div>
<p>We reach a validation accuracy of about 90%, much better than what we could achieve in the previous section with our small model trained from scratch. However, our plots also indicate that we are overfitting almost from the start  despite using dropout with a fairly large rate. This is because this technique does not leverage data augmentation, which is essential to preventing overfitting with small image datasets.</p>
<p>Now, lets review the second technique we mentioned for doing feature extraction, which is much slower and more expensive, but which allows us to leverage data augmentation during training: extending the <code>conv_base</code> model and running it end-to-end on the inputs. Note that <em><strong>this technique is in fact so expensive that you should only attempt it if you have access to a GPU: it is absolutely intractable on CPU. If you cannot run your code on GPU, then the previous technique is the way to go</strong></em>.</p>
<p>Because models behave just like layers, you can add a model (like <code>conv_base</code>) to a sequential model just like you would add a layer. So, you can do the following:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>model</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://keras.rstudio.com/reference/keras_model_sequential.html'>keras_model_sequential</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'><a href='https://keras.rstudio.com/reference/pipe.html'>%&gt;%</a></span> 
  <span class='va'>conv_base</span> <span class='op'><a href='https://keras.rstudio.com/reference/pipe.html'>%&gt;%</a></span> 
  <span class='fu'><a href='https://keras.rstudio.com/reference/layer_flatten.html'>layer_flatten</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'><a href='https://keras.rstudio.com/reference/pipe.html'>%&gt;%</a></span> 
  <span class='fu'><a href='https://keras.rstudio.com/reference/layer_dense.html'>layer_dense</a></span><span class='op'>(</span>units <span class='op'>=</span> <span class='fl'>256</span>, activation <span class='op'>=</span> <span class='st'>"relu"</span><span class='op'>)</span> <span class='op'><a href='https://keras.rstudio.com/reference/pipe.html'>%&gt;%</a></span> 
  <span class='fu'><a href='https://keras.rstudio.com/reference/layer_dense.html'>layer_dense</a></span><span class='op'>(</span>units <span class='op'>=</span> <span class='fl'>1</span>, activation <span class='op'>=</span> <span class='st'>"sigmoid"</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>This is what our model looks like now:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/summary.html'>summary</a></span><span class='op'>(</span><span class='va'>model</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>Model: &quot;sequential_1&quot;
______________________________________________________________________
 Layer (type)                  Output Shape                Param #    
======================================================================
 vgg16 (Functional)            (None, 4, 4, 512)           14714688   
                                                                      
 flatten (Flatten)             (None, 8192)                0          
                                                                      
 dense_3 (Dense)               (None, 256)                 2097408    
                                                                      
 dense_2 (Dense)               (None, 1)                   257        
                                                                      
======================================================================
Total params: 16,812,353
Trainable params: 16,812,353
Non-trainable params: 0
______________________________________________________________________</code></pre>
</div>
<p>As you can see, the convolutional base of VGG16 has 14,714,688 parameters, which is very large. The classifier we are adding on top has 2 million parameters.</p>
<p>Before you compile and train the model, its very important to freeze the convolutional base. <em>Freezing</em> a layer or set of layers means preventing their weights from being updated during training. If you dont do this, then the representations that were previously learned by the convolutional base will be modified during training. Because the dense layers on top are randomly initialized, very large weight updates would be propagated through the network, effectively destroying the representations previously learned.</p>
<p>In Keras, you freeze a network using the <code>freeze_weights()</code> function:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/cat.html'>cat</a></span><span class='op'>(</span><span class='st'>"This is the number of trainable weights before freezing"</span>,
    <span class='st'>"the conv base:"</span>, <span class='fu'><a href='https://rdrr.io/r/base/length.html'>length</a></span><span class='op'>(</span><span class='va'>model</span><span class='op'>$</span><span class='va'>trainable_weights</span><span class='op'>)</span>, <span class='st'>"\n"</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>This is the number of trainable weights before freezing the conv base: 30 </code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://keras.rstudio.com/reference/freeze_weights.html'>freeze_weights</a></span><span class='op'>(</span><span class='va'>conv_base</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/cat.html'>cat</a></span><span class='op'>(</span><span class='st'>"This is the number of trainable weights after freezing"</span>,
    <span class='st'>"the conv base:"</span>, <span class='fu'><a href='https://rdrr.io/r/base/length.html'>length</a></span><span class='op'>(</span><span class='va'>model</span><span class='op'>$</span><span class='va'>trainable_weights</span><span class='op'>)</span>, <span class='st'>"\n"</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>This is the number of trainable weights after freezing the conv base: 4 </code></pre>
</div>
<p>With this setup, only the weights from the two dense layers that you added will be trained. Thats a total of four weight tensors: two per layer (the main weight matrix and the bias vector). Note that in order for these changes to take effect, you must first compile the model. If you ever modify weight trainability after compilation, you should then recompile the model, or these changes will be ignored.</p>
<p>Now you can start training your model, with the same data-augmentation configuration that you used in the previous example.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>train_datagen</span> <span class='op'>=</span> <span class='fu'><a href='https://keras.rstudio.com/reference/image_data_generator.html'>image_data_generator</a></span><span class='op'>(</span>
  rescale <span class='op'>=</span> <span class='fl'>1</span><span class='op'>/</span><span class='fl'>255</span>,
  rotation_range <span class='op'>=</span> <span class='fl'>40</span>,
  width_shift_range <span class='op'>=</span> <span class='fl'>0.2</span>,
  height_shift_range <span class='op'>=</span> <span class='fl'>0.2</span>,
  shear_range <span class='op'>=</span> <span class='fl'>0.2</span>,
  zoom_range <span class='op'>=</span> <span class='fl'>0.2</span>,
  horizontal_flip <span class='op'>=</span> <span class='cn'>TRUE</span>,
  fill_mode <span class='op'>=</span> <span class='st'>"nearest"</span><span class='op'>)</span>

<span class='va'>test_datagen</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://keras.rstudio.com/reference/image_data_generator.html'>image_data_generator</a></span><span class='op'>(</span>rescale <span class='op'>=</span> <span class='fl'>1</span><span class='op'>/</span><span class='fl'>255</span><span class='op'>)</span>

<span class='va'>train_generator</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://keras.rstudio.com/reference/flow_images_from_directory.html'>flow_images_from_directory</a></span><span class='op'>(</span>
  <span class='va'>train_dir</span>,
  <span class='va'>train_datagen</span>,
  target_size <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>150</span>, <span class='fl'>150</span><span class='op'>)</span>,
  batch_size <span class='op'>=</span> <span class='fl'>20</span>,
  class_mode <span class='op'>=</span> <span class='st'>"binary"</span><span class='op'>)</span>

<span class='va'>validation_generator</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://keras.rstudio.com/reference/flow_images_from_directory.html'>flow_images_from_directory</a></span><span class='op'>(</span>
  <span class='va'>validation_dir</span>,
  <span class='va'>test_datagen</span>,
  target_size <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>150</span>, <span class='fl'>150</span><span class='op'>)</span>,
  batch_size <span class='op'>=</span> <span class='fl'>20</span>,
  class_mode <span class='op'>=</span> <span class='st'>"binary"</span><span class='op'>)</span>

<span class='va'>model</span> <span class='op'><a href='https://keras.rstudio.com/reference/pipe.html'>%&gt;%</a></span> <span class='fu'><a href='https://generics.r-lib.org/reference/compile.html'>compile</a></span><span class='op'>(</span>
  loss <span class='op'>=</span> <span class='st'>"binary_crossentropy"</span>,
  optimizer <span class='op'>=</span> <span class='fu'><a href='https://keras.rstudio.com/reference/optimizer_rmsprop.html'>optimizer_rmsprop</a></span><span class='op'>(</span>learning_rate <span class='op'>=</span> <span class='fl'>2e-5</span><span class='op'>)</span>,
  metrics <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>"accuracy"</span><span class='op'>)</span><span class='op'>)</span>

<span class='va'>mdl3_h5</span>          <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/file.path.html'>file.path</a></span><span class='op'>(</span><span class='va'>dir_models</span>, <span class='st'>"cats_and_dogs_small_3.h5"</span><span class='op'>)</span>
<span class='va'>mdl3_history_rds</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/file.path.html'>file.path</a></span><span class='op'>(</span><span class='va'>dir_models</span>, <span class='st'>"cats_and_dogs_small_3_history.rds"</span><span class='op'>)</span>

<span class='co'># check if already fitted and saved model</span>
<span class='kw'>if</span> <span class='op'>(</span><span class='op'>!</span><span class='fu'><a href='https://rdrr.io/r/base/files.html'>file.exists</a></span><span class='op'>(</span><span class='va'>mdl3_history_rds</span><span class='op'>)</span> <span class='op'>|</span> <span class='op'>!</span><span class='fu'><a href='https://rdrr.io/r/base/files.html'>file.exists</a></span><span class='op'>(</span><span class='va'>mdl3_h5</span><span class='op'>)</span><span class='op'>)</span><span class='op'>{</span>
  
  <span class='co'># track time to fit</span>
  <span class='va'>t0</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/Sys.time.html'>Sys.time</a></span><span class='op'>(</span><span class='op'>)</span>

  <span class='co'># fit model</span>
  <span class='va'>history</span> <span class='op'>&lt;-</span> <span class='va'>model</span> <span class='op'><a href='https://keras.rstudio.com/reference/pipe.html'>%&gt;%</a></span> <span class='fu'><a href='https://generics.r-lib.org/reference/fit.html'>fit</a></span><span class='op'>(</span>
    <span class='va'>train_generator</span>,
    steps_per_epoch <span class='op'>=</span> <span class='fl'>100</span>,
    epochs <span class='op'>=</span> <span class='fl'>30</span>,
    validation_data <span class='op'>=</span> <span class='va'>validation_generator</span>,
    validation_steps <span class='op'>=</span> <span class='fl'>50</span><span class='op'>)</span>
  
  <span class='co'># record time to fit</span>
  <span class='fu'><a href='https://rdrr.io/r/base/attr.html'>attr</a></span><span class='op'>(</span><span class='va'>history</span>, <span class='st'>"minutes"</span><span class='op'>)</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/difftime.html'>difftime</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/Sys.time.html'>Sys.time</a></span><span class='op'>(</span><span class='op'>)</span>, <span class='va'>t0</span>, units<span class='op'>=</span><span class='st'>"mins"</span><span class='op'>)</span> <span class='op'><a href='https://keras.rstudio.com/reference/pipe.html'>%&gt;%</a></span> <span class='fu'><a href='https://rdrr.io/r/base/double.html'>as.double</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'><a href='https://keras.rstudio.com/reference/pipe.html'>%&gt;%</a></span> <span class='fu'><a href='https://rdrr.io/r/base/Round.html'>round</a></span><span class='op'>(</span><span class='fl'>2</span><span class='op'>)</span>
  
  <span class='co'># save fitted model and fitting history</span>
  <span class='va'>history</span> <span class='op'><a href='https://keras.rstudio.com/reference/pipe.html'>%&gt;%</a></span> <span class='fu'><a href='https://rdrr.io/r/base/readRDS.html'>saveRDS</a></span><span class='op'>(</span><span class='va'>mdl3_history_rds</span><span class='op'>)</span>
  <span class='va'>model</span> <span class='op'><a href='https://keras.rstudio.com/reference/pipe.html'>%&gt;%</a></span> <span class='fu'><a href='https://keras.rstudio.com/reference/save_model_hdf5.html'>save_model_hdf5</a></span><span class='op'>(</span><span class='va'>mdl3_h5</span><span class='op'>)</span>
<span class='op'>}</span> <span class='kw'>else</span><span class='op'>{</span>
  <span class='co'># load previously fitted model</span>
  <span class='va'>history</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/readRDS.html'>readRDS</a></span><span class='op'>(</span><span class='va'>mdl3_history_rds</span><span class='op'>)</span>
  <span class='va'>model</span>   <span class='op'>&lt;-</span> <span class='fu'><a href='https://keras.rstudio.com/reference/save_model_hdf5.html'>load_model_hdf5</a></span><span class='op'>(</span><span class='va'>mdl3_h5</span><span class='op'>)</span>
<span class='op'>}</span>
</code></pre>
</div>
</div>
<p>Lets plot our results again:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='va'>history</span><span class='op'>)</span>
</code></pre>
</div>
<p><img src="lab4c_5.3-using-a-pretrained-convnet_files/figure-html5/unnamed-chunk-13-1.png" width="624" /></p>
</div>
<p>As you can see, we reach a validation accuracy of about 90%. This is much better than our small convnet trained from scratch.</p>
<h2 data-number="0.2" id="fine-tuning"><span class="header-section-number">0.2</span> Fine-tuning</h2>
<p>Another widely used technique for model reuse, complementary to feature extraction, is <em>fine-tuning</em>. Fine-tuning consists in unfreezing a few of the top layers of a frozen model base used for feature extraction, and jointly training both the newly added part of the model (in our case, the fully-connected classifier) and these top layers. This is called fine-tuning because it slightly adjusts the more abstract representations of the model being reused, in order to make them more relevant for the problem at hand.</p>
<figure>
<img src="https://s3.amazonaws.com/book.keras.io/img/ch5/vgg16_fine_tuning.png" alt="fine-tuning VGG16" /><figcaption aria-hidden="true">fine-tuning VGG16</figcaption>
</figure>
<p>We have stated before that it was necessary to freeze the convolution base of VGG16 in order to be able to train a randomly initialized classifier on top. For the same reason, it is only possible to fine-tune the top layers of the convolutional base once the classifier on top has already been trained. If the classified wasnt already trained, then the error signal propagating through the network during training would be too large, and the representations previously learned by the layers being fine-tuned would be destroyed. Thus the steps for fine-tuning a network are as follow:</p>
<ul>
<li><ol type="1">
<li>Add your custom network on top of an already trained base network.</li>
</ol></li>
<li><ol start="2" type="1">
<li>Freeze the base network.</li>
</ol></li>
<li><ol start="3" type="1">
<li>Train the part you added.</li>
</ol></li>
<li><ol start="4" type="1">
<li>Unfreeze some layers in the base network.</li>
</ol></li>
<li><ol start="5" type="1">
<li>Jointly train both these layers and the part you added.</li>
</ol></li>
</ul>
<p>We have already completed the first 3 steps when doing feature extraction. Lets proceed with the 4th step: we will unfreeze our <code>conv_base</code>, and then freeze individual layers inside of it.</p>
<p>As a reminder, this is what our convolutional base looks like:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/summary.html'>summary</a></span><span class='op'>(</span><span class='va'>conv_base</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>Model: &quot;vgg16&quot;
______________________________________________________________________
 Layer (type)                  Output Shape                Param #    
======================================================================
 input_1 (InputLayer)          [(None, 150, 150, 3)]       0          
                                                                      
 block1_conv1 (Conv2D)         (None, 150, 150, 64)        1792       
                                                                      
 block1_conv2 (Conv2D)         (None, 150, 150, 64)        36928      
                                                                      
 block1_pool (MaxPooling2D)    (None, 75, 75, 64)          0          
                                                                      
 block2_conv1 (Conv2D)         (None, 75, 75, 128)         73856      
                                                                      
 block2_conv2 (Conv2D)         (None, 75, 75, 128)         147584     
                                                                      
 block2_pool (MaxPooling2D)    (None, 37, 37, 128)         0          
                                                                      
 block3_conv1 (Conv2D)         (None, 37, 37, 256)         295168     
                                                                      
 block3_conv2 (Conv2D)         (None, 37, 37, 256)         590080     
                                                                      
 block3_conv3 (Conv2D)         (None, 37, 37, 256)         590080     
                                                                      
 block3_pool (MaxPooling2D)    (None, 18, 18, 256)         0          
                                                                      
 block4_conv1 (Conv2D)         (None, 18, 18, 512)         1180160    
                                                                      
 block4_conv2 (Conv2D)         (None, 18, 18, 512)         2359808    
                                                                      
 block4_conv3 (Conv2D)         (None, 18, 18, 512)         2359808    
                                                                      
 block4_pool (MaxPooling2D)    (None, 9, 9, 512)           0          
                                                                      
 block5_conv1 (Conv2D)         (None, 9, 9, 512)           2359808    
                                                                      
 block5_conv2 (Conv2D)         (None, 9, 9, 512)           2359808    
                                                                      
 block5_conv3 (Conv2D)         (None, 9, 9, 512)           2359808    
                                                                      
 block5_pool (MaxPooling2D)    (None, 4, 4, 512)           0          
                                                                      
======================================================================
Total params: 14,714,688
Trainable params: 0
Non-trainable params: 14,714,688
______________________________________________________________________</code></pre>
</div>
<p>We will fine-tune all of the layers from <code>block3_conv1</code> and on. Why not fine-tune more layers? Why not fine-tune the entire convolutional base? We could. However, we need to consider that:</p>
<ul>
<li>Earlier layers in the convolutional base encode more generic, reusable features, while layers higher up encode more specialized features. It is more useful to fine-tune the more specialized features, as these are the ones that need to be repurposed on our new problem. There would be fast-decreasing returns in fine-tuning lower layers.</li>
<li>The more parameters we are training, the more we are at risk of overfitting. The convolutional base has 15M parameters, so it would be risky to attempt to train it on our small dataset.</li>
</ul>
<p>Thus, in our situation, it is a good strategy to only some of the layers in the convolutional base.</p>
<p>Lets set this up, starting from where we left off in the previous example:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://keras.rstudio.com/reference/freeze_weights.html'>unfreeze_weights</a></span><span class='op'>(</span><span class='va'>conv_base</span>, from <span class='op'>=</span> <span class='st'>"block3_conv1"</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>Now we can start fine-tuning our network. We will do this with the RMSprop optimizer, using a very low learning rate. The reason for using a low learning rate is that we want to limit the magnitude of the modifications we make to the representations of the layers that we are fine-tuning. Updates that are too large may harm these representations.</p>
<p>Now lets proceed with fine-tuning:</p>
<p><em>BELOW IS TOO SLOW ON CPU, so not evaluating code chunks (<code>eval=F</code>)</em></p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>model</span> <span class='op'><a href='https://keras.rstudio.com/reference/pipe.html'>%&gt;%</a></span> <span class='fu'><a href='https://generics.r-lib.org/reference/compile.html'>compile</a></span><span class='op'>(</span>
  loss <span class='op'>=</span> <span class='st'>"binary_crossentropy"</span>,
  optimizer <span class='op'>=</span> <span class='fu'><a href='https://keras.rstudio.com/reference/optimizer_rmsprop.html'>optimizer_rmsprop</a></span><span class='op'>(</span>learning_rate <span class='op'>=</span> <span class='fl'>1e-5</span><span class='op'>)</span>,
  metrics <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>"accuracy"</span><span class='op'>)</span><span class='op'>)</span>

<span class='va'>mdl4_h5</span>          <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/file.path.html'>file.path</a></span><span class='op'>(</span><span class='va'>dir_models</span>, <span class='st'>"cats_and_dogs_small_4.h5"</span><span class='op'>)</span>
<span class='va'>mdl4_history_rds</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/file.path.html'>file.path</a></span><span class='op'>(</span><span class='va'>dir_models</span>, <span class='st'>"cats_and_dogs_small_4_history.rds"</span><span class='op'>)</span>

<span class='co'># check if already fitted and saved model</span>
<span class='kw'>if</span> <span class='op'>(</span><span class='op'>!</span><span class='fu'><a href='https://rdrr.io/r/base/files.html'>file.exists</a></span><span class='op'>(</span><span class='va'>mdl4_history_rds</span><span class='op'>)</span> <span class='op'>|</span> <span class='op'>!</span><span class='fu'><a href='https://rdrr.io/r/base/files.html'>file.exists</a></span><span class='op'>(</span><span class='va'>mdl4_h5</span><span class='op'>)</span><span class='op'>)</span><span class='op'>{</span>
  
  <span class='co'># track time to fit</span>
  <span class='va'>t0</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/Sys.time.html'>Sys.time</a></span><span class='op'>(</span><span class='op'>)</span>

  <span class='co'># fit model</span>
  <span class='va'>history</span> <span class='op'>&lt;-</span> <span class='va'>model</span> <span class='op'><a href='https://keras.rstudio.com/reference/pipe.html'>%&gt;%</a></span> <span class='fu'><a href='https://generics.r-lib.org/reference/fit.html'>fit</a></span><span class='op'>(</span>
    <span class='va'>train_generator</span>,
    steps_per_epoch <span class='op'>=</span> <span class='fl'>100</span>,
    epochs <span class='op'>=</span> <span class='fl'>100</span>,
    validation_data <span class='op'>=</span> <span class='va'>validation_generator</span>,
    validation_steps <span class='op'>=</span> <span class='fl'>50</span><span class='op'>)</span>
  
  <span class='co'># record time to fit</span>
  <span class='fu'><a href='https://rdrr.io/r/base/attr.html'>attr</a></span><span class='op'>(</span><span class='va'>history</span>, <span class='st'>"minutes"</span><span class='op'>)</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/difftime.html'>difftime</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/Sys.time.html'>Sys.time</a></span><span class='op'>(</span><span class='op'>)</span>, <span class='va'>t0</span>, units<span class='op'>=</span><span class='st'>"mins"</span><span class='op'>)</span> <span class='op'><a href='https://keras.rstudio.com/reference/pipe.html'>%&gt;%</a></span> <span class='fu'><a href='https://rdrr.io/r/base/double.html'>as.double</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'><a href='https://keras.rstudio.com/reference/pipe.html'>%&gt;%</a></span> <span class='fu'><a href='https://rdrr.io/r/base/Round.html'>round</a></span><span class='op'>(</span><span class='fl'>2</span><span class='op'>)</span>
  
  <span class='co'># save fitted model and fitting history</span>
  <span class='va'>history</span> <span class='op'><a href='https://keras.rstudio.com/reference/pipe.html'>%&gt;%</a></span> <span class='fu'><a href='https://rdrr.io/r/base/readRDS.html'>saveRDS</a></span><span class='op'>(</span><span class='va'>mdl4_history_rds</span><span class='op'>)</span>
  <span class='va'>model</span> <span class='op'><a href='https://keras.rstudio.com/reference/pipe.html'>%&gt;%</a></span> <span class='fu'><a href='https://keras.rstudio.com/reference/save_model_hdf5.html'>save_model_hdf5</a></span><span class='op'>(</span><span class='va'>mdl4_h5</span><span class='op'>)</span>
<span class='op'>}</span> <span class='kw'>else</span><span class='op'>{</span>
  <span class='co'># load previously fitted model</span>
  <span class='va'>history</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/readRDS.html'>readRDS</a></span><span class='op'>(</span><span class='va'>mdl4_history_rds</span><span class='op'>)</span>
  <span class='va'>model</span>   <span class='op'>&lt;-</span> <span class='fu'><a href='https://keras.rstudio.com/reference/save_model_hdf5.html'>load_model_hdf5</a></span><span class='op'>(</span><span class='va'>mdl4_h5</span><span class='op'>)</span>
<span class='op'>}</span>
</code></pre>
</div>
</div>
<p>Lets plot our results using the same plotting code as before:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='va'>history</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>We are seeing a nice 6% absolute improvement in accuracy, from about 90% to above 96%.</p>
<p>Note that the loss curve doesnt show any real improvement (in fact, its deteriorating). You may wonder, how could accuracy stay stable or improve if the loss isnt decreasing? The answer is simple: what you display is an average of pointwise loss values; but what matters for accuracy is the distribution of the loss values, not their average, because accuracy is the result of a binary thresholding of the class probability predicted by the model. The model may still be improving even if this isnt reflected in the average loss.</p>
<p>We can now finally evaluate this model on the test data:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>test_generator</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://keras.rstudio.com/reference/flow_images_from_directory.html'>flow_images_from_directory</a></span><span class='op'>(</span>
  <span class='va'>test_dir</span>,
  <span class='va'>test_datagen</span>,
  target_size <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>150</span>, <span class='fl'>150</span><span class='op'>)</span>,
  batch_size <span class='op'>=</span> <span class='fl'>20</span>,
  class_mode <span class='op'>=</span> <span class='st'>"binary"</span>
<span class='op'>)</span>

<span class='va'>model</span> <span class='op'><a href='https://keras.rstudio.com/reference/pipe.html'>%&gt;%</a></span> <span class='fu'><a href='https://keras.rstudio.com/reference/evaluate_generator.html'>evaluate_generator</a></span><span class='op'>(</span><span class='va'>test_generator</span>, steps <span class='op'>=</span> <span class='fl'>50</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>Here we get a test accuracy of 96.5%. In the original Kaggle competition around this dataset, this would have been one of the top results. However, using modern deep learning techniques, we managed to reach this result using only a very small fraction of the training data available (about 10%). There is a huge difference between being able to train on 20,000 samples compared to 2,000 samples!</p>
<h2 data-number="0.3" id="take-aways-using-convnets-with-small-datasets"><span class="header-section-number">0.3</span> Take-aways: using convnets with small datasets</h2>
<p>Heres what you should take away from the exercises of these past two sections:</p>
<ul>
<li>Convnets are the best type of machine learning models for computer vision tasks. It is possible to train one from scratch even on a very small dataset, with decent results.</li>
<li>On a small dataset, overfitting will be the main issue. Data augmentation is a powerful way to fight overfitting when working with image data.</li>
<li>It is easy to reuse an existing convnet on a new dataset, via feature extraction. This is a very valuable technique for working with small image datasets.</li>
<li>As a complement to feature extraction, one may use fine-tuning, which adapts to a new problem some of the representations previously learned by an existing model. This pushes performance a bit further.</li>
</ul>
<p>Now you have a solid set of tools for dealing with image classification problems, in particular with small datasets.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r distill-force-highlighting-css"><code class="sourceCode r"></code></pre></div>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>


<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom"></div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<div class="distill-site-nav distill-site-footer">
<p>
<a href="https://bren.ucsb.edu/"><img src="img/bren_white_logo.png" alt="Bren School logo" style="width:350px;" /></a>
</p>
<p>
  This website was made with <u><a href="https://rstudio.github.io/distill/">distill by RStudio</a></u>.
</p>
</div>
<!--/radix_placeholder_navigation_after_body-->


</body>

</html>
